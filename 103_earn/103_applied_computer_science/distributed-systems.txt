6.824

LECTURE 1
    distributed system: a set of co-opearting computers communicating over network,to get some coherent task done.
    eg. storage for websites or big data computations. or peer to peer file sharing are some of the examples.
    a lot of critical infrastructure is done this way.

    if you can solve a problem on single computer then always do it . it is easier.

    try everything else before distributed systems, they are complicated.

    distributed systems are used for performance,we want parallelism
    and to tolerate faults.make multiple computers do the same thing and if one fails,another works .

    and some problems are naturally spread across space/physical reason eg banks

    or for security goals. like i don't trust you so your stuff runs there and mine here and we communicate over internet
    hence for isolation.

    most of this course is about peformance and fault tolerance.

    there are multiple parts working concurrently hence comes with a lot of problems hence makes distributed systems hard.

    and failure patterns are unfamiliar.
    we can have partial failures.
    or some part of network is broken.hence partial failures make distributed systems hard.

    it is hard to make performance increase linearly with increase in size of system. it take a lot of careful design to do so.

    somes problems have good known solutions whereas some don't

    big websites need distributed systems.

    there is a lot to research and a lot to find and solve.
    it is nice to know distributed systems if you love building systems.
    Raft is for automatic cut over - fault tolerance.
    this course is about infrastructure for applications/that clients use.

    INFRASTRUCTURES for applications:
            STORAGE  //a lot known
            COMMUNICATION
            COMPUTATION //eg mapReduce 

    we want to simplify the tech/ build abstractions so it becomes easier to run applications
 
    the dream is to build distributed sytems that act like non distibuted system.
    the behaviour is as simple as a single machine.


    IMPLEMENTATION:
        eg remote procedure calls. RPC to mask the fact that we are communcating over a    network.
           threads //for concurrency
           concurrency control. //eg locks.

    PEFORMANCE:
        we want scalable speedup / scalbility => linear relationship between resources and performance.
        alternative is to improve code and use better algorithms which is more expensive=> to pay programmers.
        hence you have to be careful about the design

        eg web servers are easy to scale up.each server talks to DB and database is the bottleneck.hence we need some design work there. 

        it is hard of change code for performance then to use more hardware.
        replicas should be in different racks just in case a rack crashes.
    FAULT TOLELRANCE:
        a single computer can run for years without going down.
        but if you have thousands of computers,odds are high that you will have some failed machine everyday.

        something will go wrong everyday
        and there are hundred of switches and wires and things to wrong everytime.

        we have to make fault tolerance part of the design.

        AVAILABLITY:
            we want system to keep operating even when failure happens.eg using replicas.
        RECOVERABILITY:
            if something goes wrong,someone fixes things and it starts working again. eg using logs to recover.
        
        although there is threshold for both.
        good available system is recoverable as well.
        non volatile storage is used for logging state of the system.
        and we use clever ways to make sure performance of non volatile storage is not a problem
        and replication is used for availablity.

        problem with replicas:
            replicas stop acting like replicas and are little different.
    
    CONSISTENCY:
        eg key value service, put(key,value), get(key).with multiple copies of data.
                              using put to one replica and updates the value and before sending to another replica
                              the sender fails hence now we have different data for same key in the replicas hence
                              inconsistant data.

                              hence we need to define get,and put appropriately and what they do.

                              strongly consistent system: get recent put  //very hard to achieve,needs fast communication,might need to read all replicas.

                              weakly consistant system: you might see old put for some time. a lot of systems are fine being weakly conisistent.
                              

        whenver designing replicas make sure their failure probability is independent of each other
        like put them in different racks.or for functioning they shouldn't be dependent on each other strongly.
        put them in different cities or parts of continent so no earthquake issues.but now the commication is slower.

        systems in real life are often very weak.

    
    MAPREDUCE: CASE STUDY

    originally designed by google. around 2004
    for computation on tera bytes of data for indexing for their search engine.
    or for analysing the web to rank pages.
    indexing is like sorting.

    they were using thousands of computers to do so.
    but they needed to code distributed algorithms.

    hence they were looking for a framework for any person to write query
    to this system without caring about distribtion and hence mapreduce
    would take care of it,and all you do is write a map and a reducer.


    the assumption is that 
    data is like
     input file 1
     input file 2
     input file 3
     and map works on each input file and it produces a list of key value pair as output.
     eg for wordcount problem, key is the word and value is 1
     each map produces an output for each key and value from that input only

     now collect all instances from all maps and produce key and value list.
     and is handed to reduce, where each list is given to different reducer.
     one call to reduce for every key.
      eg for wordcount it would to count the number of items in list.
      hence each reducer will produce a count for that key/word.

    this whole process is called a JOB and each map call or reduce call is called TASK

    Map(K,V)
    key is the file name which is typically ignored 
    and V is value of input file
    for word count split V into words and for each word
    emit(word,"1")
    
    Map is now just a function that anyone can write.
    it needs to know nothing about the distributed sytem hence making it look like one system.

    Reduce(K,V) //the key is the word and value is the list from all instances across all input files.
    emit(len(V))

    like map this also is just a functions.
    
    
    for a longer job you can pipeline a lot of map reduce jobs.

    sometimes the algorithm might not be easy to conform it to map reduce form. after all map and reduce are pure functions.
    you might need to use multiple map reduce and or use other tools as well.

    programmer only sees map and reduce.and doesn't need to care about internals which is cool.

    there are thousands of worker servers and a master server.
    master server commands to worker server to run given map function on given file.
    and worker produces a file locally that it generates using emit() 
    then the workers rearrange these files for reduce phase.each worker agrees on which keys it will run reduce on and every 
    other worker node has to send data to other worker nodes based on that information.hence 
    workers call reduce on all keys that it is alloted to work on.
    and writes in a new file in this distributed file system.where this whole thing acts as one file from all workers.

    google used GFS google file service,which splits file into 64 MB chunks distributed uniformly over cluster.
    hence for map reduce to work data is already in desired form.

    same machines run GFS and map reduce.
    each workers map works on related data stored on it.
    data usually is transfered in gigabit speed in these clusters.

    network throughout has been the bottleneck for this system in paper.

    map reduce is not just about hadoop.
    shuffle is what happens after map.

    the goal was to make it easy to program by people who have no idea what was going on underneath.

    mapreduce doesn't take advantage of streaming.
    and shuffle is what needs the network communication.
    output of reduce is also stored in GFS.
    hence another round of network used to store output on GFS,since copies needed for fault tolerance and to be stored across machines.

    modern data centers have fast network throughput so no need to run GFS and mapper on same machine.hence can be on different machines.

    google no longer uses GFS.

    mapreduce doesn't take advantage of streaming and mapper etc work in batches.

LECTURE 2: RPC and threads
    we are using GO for labs
        good support for threads and locking and convenient remote procedure call package.
        it is type safe and memory safe.
        it is garbage collected.
        combination of threads and garbage collections is important.
        in c++ you can't free memory until last thread that is using that obbject stops working with it.
        and the langauge is simpler than c++
    
    in distributed computing,a remote procedure call is when a computer program causes another procedure to execute in a different address space usually on another computer on a shared network,which is coded as if it were a normal local procedure call,it is a client-server interaction.it is a form of inter proess communiction(IPC) each language has package for this,can be encoded in json etc as well.

    THREADS:
        threads are the main tool to manage concurrency.
        in GO threads are called go routines.
        threads share address space.
        threads have separate stack and pointers.
        since they share address space,in principle they can access each others stack but we don't usually do that.
        we use threads for multicore parallelism.

        I/O concurrency:
            waiting for multiple replies at a time./multiple inputs taken simulatenously
            and sending from multiple threads simultanoesly in the network
            threads can share a port but usually we don't do that,as that would be a bottleneck.

        also to be doing something in background,instead of using that thing in main program and writing 
        checks directly in main program,it should do checks in background.
        like sleep for a second and do something again.we write a thread in background to do so.

        another line of thinking is to do asynchornous programming/ event driven programming.
            it has a single thread and single loop that waits for anything that triggers something.
        
        threads are usually more linear and convinient to program and with asynchrous cannot be used to
        harness multiple cores.

        to use both parallalism and asynchornous, we can create as many threads as the no. of processors and 
        each using event driven programming.
        10 threads are good.

        thread challenges:
            since they share data. it is sometimes critical. threads can share a cache.
            it is very easy to get bugs where you share memory.
            eg modifying the shared variable n=n+1 , it is called RACE condition.
            can be solved using locks/mutexes.
            mut.lock()
            n=n+1
            mut.unlock()

            hence making it atomic.
            lock can be interior to a data structure if we want it to be that and it is a reasonbale strategy.although the programmer might use outside as well as he/she is unfamiliar with the internal locks.and if datastructures use each other with locks,there might be a deadlock.

            another problem with threads could be co-ordination.
            you want another thread to wait until another thread generates the data.

            we can use condition variables,to kick threads based on condition of wait call.

            deadlock is also a problem with threads. and you run into this problem a lot.
            
            it is very difficult to find RACE as problem could happen once in billion. so we use automated tools to find them.

            you can use shared memory or channels for threads to communicate.
            you might not need locks in this way.
            
LECTURE 3: GFS: case study: how to build big storage.
    storage is one of the most important abstraction when it comes to distributed systems.

    and it was a sucess and was used for a long time in real,world.

    WHY IS IT HARD?
        there are a lot of things to get right.
        we want peformance,since disks are really slow usually
            done using sharding=>splitting data across machines with replication.
        we want fault tolerance:
            using replication.
            and they should be in sync.
            with replication we risk consistency.
        we want conisistency and we pay for it with low performance.

        the ideal behaviour is like as if it is just one server with one copy of data => strong consistency.

    BAD REPLICATION DESIGN:
                we have two servers each with a replicated database and we want to keep them in sync.
                now if you want to update both the databases and one of the update request fails,we get incosistent databases.

    GFS:
        we had academia till then but nothing in practise.

        gfs fixes it,we get better but not perfect design
        it was built in 2003

        given a vast dataset that cannot be stored on a single disk.
        they had logs,indexes,web pages etc.

        now they wanted to process them quickly using map reduce.
        
        hence they wanted a big and fast storage system that was general and can be used for any application,hence it should be reusable.

        they didn't want tailored system for their specific need.

        to do bigness and fastness they needed to split the data into multiple machines. 
        even a single file would get split and,
        failure recovery should be automatic.

        GFS was designed to run on a single data center / machine room

        it was for internal use only .

        paper was publised in 2003

        these ideas were not new.

        but it described a system that was already built hence makes it a milestone.

        it used a single master. //there might be a replica of master though.
        it didn't gurantee consistanty.
        google search can get away with inconsitencies and a bank cannot.


        client                             master
                        chunk server 1, chunk server 2, chunk server 3



        MASTER:

            it keeps table that maps
                filename to array of chunk handles.
            anther table that maps:
                handle: lsit of chunkservers versions numbers and which one is primary and primary is only primary for lease time.
            
            master stores this data in memory and disk.

            keeps logs for checkpoints in disk.

            even the chunk servers know what chunks of which files they have so no need to store in disk.
            lease expiration is for chunks then next chunk is primary,one where people read and perform computation on.
            logs are fast writes.append to logs is fast.thats how logs are usually designed.


        READ:
            application/client has a file name and offset in mind and wants to read it from that offset.
            these are send to master,and master return chunk handle and the list of servers to read from,client can read from any of them.

            client caches these results to avoid asking master same info again and again.

            now client asks the chunk server for that chunk and tells it the offset,
            and chunk server has these files in ordinary linux files with handle as the name of that files,each chunk as a file.
            and returns the data to the client.

            client would try to get chunks from different server on same rack in data house.

        WRITES:

            client wants to append something to a file.

            client asks the master that it wants to append and asks it for last chunk.
            
            for writing we only need to write to primary.

            if no primary system,then you have to update the most up to date chunk ones.

            first step is to find up to date replica chunk=> this is happening in master.

            master has version numbers so it can figure out which one has the up to date.

            each chunk also know the verison number of chunks it has.

            picks the primary,rest being secondary. the master increment the version number in disk and it sends to client.
            that here is the primary with this version so update yourself.

            client data is send to primary and secondary and data is stored in temporary files and then primary writes to end and tells all other to do the same.

            once all secondaries reply sucess to primary and primary then replies sucess to client.
            if any of them fails hence primary sends it failed,then client is supposed to reissue the request.
            three replicas per chunk by default.

            master was the limitation as there was a single master.
            and load on single master increasesd.

            split brain problem: when two machines think they are primary.
                usually due to network partition.
            
LECTURE 4: PRIMARY BACKUP REPLICATION of program : fault tolerance
    if something crashes we still want availablity
    and our tool would be replication.

    by failure we mean failure of a single computer.
        the computer simpy stops executing and that doesn't 
        mean it is computing wrong results.
        fail stop -> it stopped working
        
        eg. fan failed hence the cpu.
    
    we are not covering the 
        bugs in software and design issues in hardware.

    replication cannot help with bugs.

    same for the case when hardware computes incorrectly.

    kernel panic is also covered under here.

    disks have error correction codes in case of bit flip 
    same for network we have checksum.

    there certainly are limitations to replicas.
    we think failure in one machine is independent of each other.

    there could be a corelation that failures hence if one fails 
    then all fail
    same for building buring down or an earthquake
    hence for such cases we need replicas over distance.


    is replication worth it?
        since it uses thrice as much as disk space.
        it is an economic question
             it depends on the value of having online service.
        things depend on the consequence of failure.
        and ofcourse the cost.

    approaches to replication:
        state transfer.
            given replicas of machine.
            the primary sends the copy of its state/RAM and it is saved in case something wrong happens,this is send over 
            network for backup
        
        replicated state machines.
            something unexpected happens only when there is something
            wrong in external events/inputs
            hence you only backup those external events.
            or operations.
            operations are smaller than the states,hence this one is 
            very efficient,although the assumptions are too strict.
        
        this lecture is about uniprocessors:

        state transfer is more robust.

        in state transfer backup could lag during failure,hence when we start it it would not be in same state.

        making the synchronization absolute is a gigantic task.

        if primary fails switch to backup elegantly server:
            there is going to be an anomoly during the cut over.in ideal world we want nobody to notice.
        
        and even second replica can fail hence we need third replica up now.
        and the state is transfered to it and it is gonaa be expensive 
        to transfer whole state.

        what state to replicate:
             we can be replicating every single thing machine are doing,every single bit of state,we don't care what is running on it,we are even replicating the register.
             eg vmware replication.

        HOW VMWARE FT WORKS:
            VMWARE is virutal machine company,this was their starting point.

        in the paper:
            we have two machines running.
            client sends request to primary
            Virtual machine monitor(VMM) get the request 
            and it sends the copy to backup VMM monitor.
            and now both have the same copy of the input 
            and both will process it the same way and be 
            in synchronization.

            primary would send reply to the client.
            and so does the backup,but the VMM drops that packet.
            this sending from primary to backup are called log events
            on log channel.

        fault tolerance:
            if primary crashes,it stops getting log entries
            which are usually periodic. say 100 times a second

            VMM monitor on backup figures out that the primary must
            be dead so the backup goes live.

            and now future requests goes to backup from now on 
            and our backup has taken over.

            if the backup fails similarly 
            the primary would abandom the backup.

            backup could take over by claiming primary's ethernet id.


        NON DETERMINISTIC EVENTS THAT MIGHT HAPPEN:
            inputs from external source.
                that is why we are replicating in the first place.
                otherwise if there is no state,we can start new server
                directly.
            recieving packets is basically an interrupt to cpu.

            weird instructions:
                like random number generator.
            multicore parallelism
                this is uniprocessor system only
                because then the service would be running on multicore
                and the intructions could be interleving and could
                cause different results.
                eg. getting locks before one another in program
                different threads can get locks at different times
            
            log entry:
                instruction number at which interrupt occured. since the boot
                type
                data/packet
            
            interrupts have to occur at the instruction time,
            if we want them to not divege.

            VMM keeps track of these and sends to backup
            and backup VMM has to do the same,it arranges with
            cpu to cause the interrupt at the same instruction.
            it might need some hardware support.to ask cpu to interrupt say after 1000 intstructions. all intel chips
            now support it. this can be used to profile cpu as well.

            VMM can be used to do what we learned in this lecture.

            backup is always behind the primary.

            NIC usually DMA'S data in the RAM.
            we can't allow that in this case as we don't have control over such events hence cannot be replicated.
            so we store them in virtual machine monitors private memory and then it writes to our VMM memory deterministically so it can be replicated

        failure at awkward time is the crux of problems in distributed systems.
        output rule: the primary cannot reply to client before sending log to backup.    m,8

        all these processing is happening in VMWare,VMWare is written in C.

        this syncronous wait can be a peformance issue.
        at this level servers don't have ip addresses.
        as they are in LAN,and they communcate with MAC addresses.

    if primary and replica cannot communicate,then we have split 
    brain disaster and each one of them acts as if they are the ones who is alive:
         to solve this there is an outside authority that decides which one is the real one.
         eg putting Test and Set flag in disk that they share,and one that acquires gets to live.or we can have TESt and set server.
    
LECTURE 5 : GO AND CONCURRENCY
    using threads can sometimes makes problem easier.
    threads don't necessarily make things complex.
    it might simplify things.

LECTURE 6: FAULT TOLERANCE: RAFT : how to get state machine replication correct.
    single point of failure is a problem very often. good thing about one master is that is that it can't disagree with itself,hence more consistent. test and set server in VMWARE FT was the single point of failure.

    the goal is to avoid split brain.

    we can build replicated test and set server.

    split brain-> two test and set servers and two clients are there
        and clients want to know who is the primary.
        split brain arises when a client can talk to one but not other.
        how should the system react ?
        as modifying one and not other will make the system inconsistent.
        but if you need it to talk to both in order to make progress.
        it is then no better than having a single server.

        hence waiting to both is a bad solution.
        and talking to one and marking another as bad is not also 
        a good solution and the problem could be the network,and different clients could be talking to different test and set servers. hence split brain.
        as client always sends to both.

    solutions:
        network that could not fail
            eg. wires in your laptop
                or in your data houses.
            we can rule out split brain.
            hence if you cannot talk to both servers then,it must be
            down.
        second solution would be some kind of human intervention
            human looks at machines and verifes if one of them is down
            or turns off of them down.
        partition: when these servers cannot talk to each other

        majority vote solution:
            have odd number of servers,hence no symmetry.
            and majority rules.
            majority decides the next step
            it works even in case of partition.

            the majority is always out of all not just ones that are live,even if some of them have failed.
            given 2f+1 servers you can stand f failures. often called quarum systems as 2 out of 3 is called a quarum.
            
            raft is closer to this idea.
        
            raft relies on the fact that any two majorities will have atleast one server in common.
            raft was proposed in 1990's raft's idea was to deal with split brain.
            paxos was first such system,and vsr,view stand replication. being used in industry since 2005.
        RAFT:
            takes form of a library.
            raft is a consensus algorithm.
            raft libraries coordinate with each other.
            the server has some state and raft that recieves rpc's from clients.

            clients can send put and get requests to leader server.
            the request is recieved by raft and they raft replicas chit chat and put the request in their logs and then the request is commited in all replicas and at this point it is ok to execute it.and leader then sends the reply to the client.and all replicas do the operation from log.

            logs help in doing things in order,and log has numbered slots,so it has track if anything got lost.

            